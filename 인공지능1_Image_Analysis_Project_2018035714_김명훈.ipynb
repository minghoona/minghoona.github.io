{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "인공지능1_Image Analysis Project_2018035714_김명훈.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minghoona/minghoona.github.io/blob/master/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A51_Image_Analysis_Project_2018035714_%EA%B9%80%EB%AA%85%ED%9B%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr94URydKkIY"
      },
      "source": [
        "##한양대학교 산업융합학부 정보융합전공 2018035714 김명훈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twawzwx1Kcuu"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBzRhCdNKcuu"
      },
      "source": [
        "import os\n",
        "\n",
        "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
        "MODELS_DIR = os.path.join(DATA_DIR, 'models')\n",
        "for dir in [DATA_DIR, MODELS_DIR]:\n",
        "    if not os.path.exists(dir):\n",
        "        os.mkdir(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u7nH7uYKcuv"
      },
      "source": [
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "# Download and extract model\n",
        "MODEL_DATE = '20200711'\n",
        "MODEL_NAME = 'ssd_resnet101_v1_fpn_640x640_coco17_tpu-8'\n",
        "#MODEL_NAME = 'ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8'\n",
        "\n",
        "MODEL_TAR_FILENAME = MODEL_NAME + '.tar.gz'\n",
        "MODELS_DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/'\n",
        "MODEL_DOWNLOAD_LINK = MODELS_DOWNLOAD_BASE + MODEL_DATE + '/' + MODEL_TAR_FILENAME\n",
        "PATH_TO_MODEL_TAR = os.path.join(MODELS_DIR, MODEL_TAR_FILENAME)\n",
        "PATH_TO_CKPT = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'checkpoint/'))\n",
        "PATH_TO_CFG = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'pipeline.config'))\n",
        "if not os.path.exists(PATH_TO_CKPT):\n",
        "    print('Downloading model. This may take a while... ', end='')\n",
        "    urllib.request.urlretrieve(MODEL_DOWNLOAD_LINK, PATH_TO_MODEL_TAR)\n",
        "    tar_file = tarfile.open(PATH_TO_MODEL_TAR)\n",
        "    tar_file.extractall(MODELS_DIR)\n",
        "    tar_file.close()\n",
        "    os.remove(PATH_TO_MODEL_TAR)\n",
        "    print('Done')\n",
        "\n",
        "# Download labels file\n",
        "LABEL_FILENAME = 'mscoco_label_map.pbtxt'\n",
        "LABELS_DOWNLOAD_BASE = \\\n",
        "    'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'\n",
        "PATH_TO_LABELS = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, LABEL_FILENAME))\n",
        "if not os.path.exists(PATH_TO_LABELS):\n",
        "    print('Downloading label file... ', end='')\n",
        "    urllib.request.urlretrieve(LABELS_DOWNLOAD_BASE + LABEL_FILENAME, PATH_TO_LABELS)\n",
        "    print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOS2pmp_Kcuw"
      },
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTZz5CTFKcuw"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0qFNpUAKcux"
      },
      "source": [
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K18YmLV0Kcux"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "while True:\n",
        "    # Read frame from camera\n",
        "    ret, image_np = cap.read()\n",
        "\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'][0].numpy(),\n",
        "          (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
        "          detections['detection_scores'][0].numpy(),\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=200,\n",
        "          min_score_thresh=.30,\n",
        "          agnostic_mode=False)\n",
        "\n",
        "    # Display output\n",
        "    cv2.imshow('object detection', cv2.resize(image_np_with_detections, (800, 600)))\n",
        "\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}